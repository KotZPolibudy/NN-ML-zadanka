{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebvqJaNU9bkH"
   },
   "source": [
    "# Wprowadzenie do sieci neuronowych i uczenia maszynowego\n",
    "\n",
    "## Lab: Własne moduły w PyTorch, regularyzacja i autoenkodery\n",
    "\n",
    "---\n",
    "\n",
    "**Autorzy materiałów:** Marek Wydmuch, Iwo Błądek, Jakub Bednarek<br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Ćwiczenia wykonane przez: \\\n",
    "Wojciech Kot 151879 \\\n",
    "Julia Samp 151775 \\\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8aSyboqZ40M"
   },
   "source": [
    "## Uwaga\n",
    "\n",
    "* **Aby wykonać polecenia należy najpierw przejść do trybu 'playground'. File -> Open in Playground Mode**\n",
    "* Nowe funkcje Colab pozwalają na autouzupełnianie oraz czytanie dokumentacji.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wlq47LA0BuBB"
   },
   "source": [
    "## Cel ćwiczeń:\n",
    "\n",
    "- zapoznanie się z tworzeniem własnych modułów w PyTorch\n",
    "- wykorzystanie podstawowych mechanizmów regularyzacji: Dropout i Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8ToIOrDr7A8",
    "outputId": "65b05f1d-4d9e-458c-cf48-c714a6ecc983"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ru_6o1FtcJb1",
    "outputId": "b6840fe6-a5a9-46e1-f1de-a2678ccef6ed"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6704VllCgACt"
   },
   "source": [
    "## Własne moduły (warstwy sieci neuronowych) w PyTorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Djf05n2ljXCu"
   },
   "source": [
    "Na poprzednich zajęciach używaliśmy gotowych modułów reprezentujących warstwy sieci neuronowych by stworzyć główny moduł naszego modułu.\n",
    "\n",
    "W PyTorch nie ma żadnej hierarchii modułów (jak np. w TensorFlow czy Keras, gdzie API jest podzielone na modele i warstwy). Każdy moduł może używać innych modułów jako swoich komponentów.\n",
    "\n",
    "Poniżej przykładowa implementacja modułu warstwy liniowej całkowicie od podstaw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOZf2KXSf_zF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        # Parametry (wagi) naszego modułu\n",
    "        self.weights = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        # Inicjalizacja wag\n",
    "        nn.init.xavier_normal_(self.weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return torch.mm(x, self.weights)\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            CustomLayer(784, 512),\n",
    "            nn.ReLU(),\n",
    "            CustomLayer(512, 512),\n",
    "            nn.ReLU(),\n",
    "            CustomLayer(512, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67epDtrvAd-I",
    "outputId": "074b90f6-8c7a-438f-f910-45af74c3427c"
   },
   "outputs": [],
   "source": [
    "# Setup naszego modelu\n",
    "model = CustomModel(num_classes=10).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128)\n",
    "\n",
    "def accuracy(pred, target):\n",
    "    return (pred.argmax(1) == target).type(torch.float).sum().item()\n",
    "\n",
    "# dodane do problemów z zad 6 i device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Pętla treningowa i testowa\n",
    "def train_and_test(\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        metric=None,\n",
    "        epochs=10,\n",
    "        verbose=False\n",
    "    ):\n",
    "    epochs_history = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_metric = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(data)\n",
    "            loss = criterion(pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if verbose and batch_idx % 100 == 0:\n",
    "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            train_metric += metric(pred, target)\n",
    "        if verbose:\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            train_metric /= len(train_loader.dataset)\n",
    "            print(f\"Train loss: {train_loss:.4f}\")\n",
    "            print(f\"Train {metric.__name__}: {train_metric:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        test_metric = 0\n",
    "        test_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            pred = model(data)\n",
    "            loss = criterion(pred, target)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            test_metric += metric(pred, target)\n",
    "        if verbose:\n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            test_metric /= len(test_loader.dataset)\n",
    "            print(f\"Test loss: {test_loss:.4f}\")\n",
    "            print(f\"Test accuracy: {test_metric:.4f}\")\n",
    "            print(\"-------------------------------\")\n",
    "\n",
    "        epochs_history.append({\n",
    "          \"epoch\": epoch,\n",
    "          \"train_loss\": train_loss,\n",
    "          f\"train_{metric.__name__}\": train_metric,\n",
    "          \"test_loss\": test_loss,\n",
    "          f\"test_{metric.__name__}\": test_metric\n",
    "        })\n",
    "    return epochs_history\n",
    "\n",
    "_ = train_and_test(train_loader, test_loader, model, optimizer, criterion, metric=accuracy, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0X-U_vfAEde"
   },
   "source": [
    "### Zadanie 1\n",
    "\n",
    "Stwórz prosty model\n",
    "- warstwy konwolucyjnej (Conv2D): 32 filtry 3x3,\n",
    "- konwolucyjnej: 64 filtry 3x3,\n",
    "- warstwy MaxPooling (MaxPooling2D): 2x2\n",
    "- warstwy ukrytej gęstej (Dense): 128 neuronów,\n",
    "- warstwy wyjściowej.\n",
    "\n",
    "Ważne:\n",
    "- w każdej warstwie poza warstwą wyjściową funkcją aktywacji powinno być relu,\n",
    "- funkcja aktywacji dla warstwy wyjściowej to softmax,\n",
    "- między częścią konwolucyjną a gęstą trzeba spłaszczyć tensor przy pomocy warstwy `nn.Flatten`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oi-_IKIhBLbf",
    "outputId": "b0da1828-a2f5-47ee-fd73-baf4835b20cc"
   },
   "outputs": [],
   "source": [
    "class CustomConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0):\n",
    "        super(CustomConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class CustomDense(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            CustomConv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            CustomConv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            CustomDense(in_features=64 * 14 * 14, out_features=128),\n",
    "            nn.Linear(in_features=128, out_features=num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "\n",
    "    # Inicjalizacja parametrów, która znacząco poprawi początkowe uczenie\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = SimpleModel(num_classes=10).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "_ = train_and_test(train_loader, test_loader, model, optimizer, criterion, metric=accuracy, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTjsGT9QGCtW"
   },
   "source": [
    "## Zadanie 2\n",
    "\n",
    "Na podstawie powyższego przykładu stwórz moduł bloku ResNet.\n",
    "Zadbaj o to by rozmiary tensorów po warstwach konwolucyjnych się nie zmieniały.\n",
    "\n",
    "![resnet](https://miro.medium.com/max/1000/1*6HDuqhUzP92iXhHoS0Wl3w.png)\n",
    "\n",
    "Zmodyfikuj model z zadania 1, zamieniając warstwy konwolucyjne na dwa modele bloku ResNet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "xMZZ-2SIPz7V",
    "outputId": "fd20584c-90df-4f7b-d138-df50eb82952c"
   },
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.layers(x)\n",
    "        out = self.relu(out + identity) # tu pojawia się problem wymiarowości out i identity\n",
    "        return out\n",
    "\n",
    "class CustomDense(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            ResNetBlock(in_channels=1, out_channels=32),\n",
    "            ResNetBlock(in_channels=32, out_channels=64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            CustomDense(in_features=64 * 14 * 14, out_features=128),\n",
    "            nn.Linear(in_features=128, out_features=num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "\n",
    "    # Inicjalizacja parametrów, która znacząco poprawi początkowe uczenie\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = SimpleModel(num_classes=10).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "_ = train_and_test(train_loader, test_loader, model, optimizer, criterion, metric=accuracy, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqIntmmWEUaB"
   },
   "source": [
    "## Regularyzacja\n",
    "\n",
    "### Zadanie 3\n",
    "\n",
    "Rozszerz model stworzony w zadaniu 1 o dwie warstwy Dropout (nn.Dropout):\n",
    "- jedna po warstwie MaxPooling (wartość współczynnika odrzucenia 0.25)\n",
    "- druga po gęstej warstwie ukrytej (Dense), wartość współczynnika odrzucenia 0.5.\n",
    "- dodaj opcję włączenia i wyłączenia dropoutu jako argument konstruktora modułu modelu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_7oo2C5H8sQ"
   },
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_after_pooling=True, dropout_after_dense=True):\n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "        layers = [\n",
    "            CustomConv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            CustomConv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        ]\n",
    "\n",
    "        if dropout_after_pooling:\n",
    "            layers.append(nn.Dropout(p=0.25))\n",
    "\n",
    "        layers.append(nn.Flatten())\n",
    "        layers.append(CustomDense(in_features=64 * 14 * 14, out_features=128))\n",
    "\n",
    "        if dropout_after_dense:\n",
    "            layers.append(nn.Dropout(p=0.5))\n",
    "\n",
    "        layers.append(nn.Linear(in_features=128, out_features=num_classes))\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    # Inicjalizacja parametrów, która znacząco poprawi początkowe uczenie\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = SimpleModel(num_classes=10).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "_ = train_and_test(train_loader, test_loader, model, optimizer, criterion, metric=accuracy, epochs=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRuy70AoHEAB"
   },
   "source": [
    "### Zadanie 4\n",
    "Rozszerz model stworzony w poprzednich zadaniach o dwie warstwy Batch normalization (nn.BatchNorm2d) po warstwach konwolucyjnych. Dodaj opcję włączenia i wyłączenia dropoutu jako argument konstruktora modułu modelu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pzIwT0tH9fH",
    "outputId": "1dbf0416-a4b4-4b20-dc57-94d632675279"
   },
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_after_pooling=True, dropout_after_dense=True, use_batchnorm=True):\n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "        layers = [\n",
    "            CustomConv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        ]\n",
    "\n",
    "        if use_batchnorm:\n",
    "            layers.append(nn.BatchNorm2d(32))\n",
    "\n",
    "        layers.append(CustomConv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1))\n",
    "\n",
    "        if use_batchnorm:\n",
    "            layers.append(nn.BatchNorm2d(64))\n",
    "\n",
    "        layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        if dropout_after_pooling:\n",
    "            layers.append(nn.Dropout(p=0.25))\n",
    "\n",
    "        layers.append(nn.Flatten())\n",
    "        layers.append(CustomDense(in_features=64 * 14 * 14, out_features=128))\n",
    "\n",
    "        if dropout_after_dense:\n",
    "            layers.append(nn.Dropout(p=0.5))\n",
    "\n",
    "        layers.append(nn.Linear(in_features=128, out_features=num_classes))\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    # Inicjalizacja parametrów, która znacząco poprawi początkowe uczenie\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = SimpleModel(num_classes=10).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "_ = train_and_test(train_loader, test_loader, model, optimizer, criterion, metric=accuracy, epochs=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzizHr8YHSge"
   },
   "source": [
    "### Zadanie 5\n",
    "Porównaj model bez oraz z różnych kombinacjami technik regularyzacji (z dropoutem ale bez batch norm., bez dropout ale z batch norm., z dropoutem i z batch norm.).\n",
    "Stwórz cztery wykresy:\n",
    "- błąd funkcji celu dla zbioru treningowego,\n",
    "- błąd funkcji celu dla zbioru walidacyjnego,\n",
    "- trafność klasyfikacji dla zbioru treningowego,\n",
    "- trafność klasyfikacji dla zbioru walidacyjnego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "x9JBF4euH9vu",
    "outputId": "5505d87f-dae5-4575-f0f2-990ba4ea6360"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_split(history_list, label_list):\n",
    "    epochs = [entry['epoch'] for entry in history_list[0]]\n",
    "\n",
    "    plt.figure()\n",
    "    for history, label in zip(history_list, label_list):\n",
    "        train_loss = [entry['train_loss'] for entry in history]\n",
    "        plt.plot(epochs, train_loss, label=f\"Train {label}\")\n",
    "    plt.title(\"Błąd funkcji celu - Zbiór treningowy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    for history, label in zip(history_list, label_list):\n",
    "        test_loss = [entry['test_loss'] for entry in history]\n",
    "        plt.plot(epochs, test_loss, label=f\"Test {label}\")\n",
    "    plt.title(\"Błąd funkcji celu - Zbiór testowy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_split(history_list, label_list):\n",
    "    epochs = [entry['epoch'] for entry in history_list[0]]\n",
    "\n",
    "    plt.figure()\n",
    "    for history, label in zip(history_list, label_list):\n",
    "        train_accuracy = [entry['train_accuracy'] for entry in history]\n",
    "        plt.plot(epochs, train_accuracy, label=f\"Train {label}\")\n",
    "    plt.title(\"Trafność klasyfikacji - Zbiór treningowy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    for history, label in zip(history_list, label_list):\n",
    "        test_accuracy = [entry['test_accuracy'] for entry in history]\n",
    "        plt.plot(epochs, test_accuracy, label=f\"Test {label}\")\n",
    "    plt.title(\"Trafność klasyfikacji - Zbiór testowy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "models = [\n",
    "    SimpleModel(num_classes=10, dropout_after_dense=False, dropout_after_pooling=False, use_batchnorm=False).cuda(),\n",
    "    SimpleModel(num_classes=10, use_batchnorm=False).cuda(),\n",
    "    SimpleModel(num_classes=10, dropout_after_dense=False, dropout_after_pooling=False).cuda(),\n",
    "    SimpleModel(num_classes=10).cuda()\n",
    "]\n",
    "\n",
    "label_list = [\n",
    "    \"Model bez 'dodatków'\",\n",
    "    \"Model z Dropoutem (bez BatchNorm)\",\n",
    "    \"Model z BatchNorm (bez Dropoutu)\",\n",
    "    \"Model z Dropoutem i BatchNorm\"\n",
    "]\n",
    "\n",
    "history_list = []\n",
    "for model, name in zip(models, label_list):\n",
    "    print(f\"Trening modelu: {name}\")\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    history = train_and_test(train_loader, test_loader, model, optimizer, criterion, metric=accuracy, epochs=10)\n",
    "    history_list.append(history)\n",
    "\n",
    "# Rysowanie wykresów\n",
    "plot_loss_split(history_list, label_list)\n",
    "plot_accuracy_split(history_list, label_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRXbmNFsKxsL"
   },
   "source": [
    "## Autoenkodery\n",
    "\n",
    "Ideę autoenkodera prezentuje poniższy rysunek:\n",
    "![label-autoencoder_schema](https://drive.google.com/uc?export=view&id=1Ai2ER1ppKfnHg5t_lCwO_fvvFNe59dgd)\n",
    "\n",
    "Widzimy tutaj, że obrazek ze zbioru MNIST o rozmiarze 28 x 28 został skompresowany przez **enkoder** do tensora o rozmiarze 5 x 2. Tensor ten nosi nazwę **wektora zmiennych ukrytych** (ang. latent vector). Następnie **dekoder** przyjął ten wektor na wejście, i odtworzył oryginalny obrazek. Jest to przykład zadania **autoasocjacji**, gdzie celem uczenia sieci neuronowej jest możliwie wierne odtworzenie danych wejściowych. Zadanie to może się wydawać bez sensu w odosobnieniu (po co odtwarzać coś, co już mamy?), jednak to co nas najbardziej interesuje w autoenkoderze to wektor zmiennych ukrytych. Jako że skompresowaliśmy cały obrazek do 10 wartości, to by realistyczne odtworzenie z nich oryginalnego obrazka było możliwe, każda z tych wartości musi 1) zawierać o nim możliwie dużo informacji, 2) nieistotne detale oryginalnego obrazka muszą zostać pominięte. Wyciągnęliśmy więc z danych informacyjną \"esencję\", pozbyliśmy się redundatnych elementów opisu.\n",
    "\n",
    "<br>\n",
    "\n",
    "Najważniejszą cechą autoenkodera jest właśnie **uczenie się efektywnego kodowania danych**, co zazwyczaj wiąże się z redukcją wymiarowości (tzw. 'undercomplete autoencoders'), choć można też uczyć autoenkodery o kodowaniu zwiększającym wymiarowość (tzw. 'overcomplete autoencoders'). Skupimy się na autoenkoderach zmniejszających wymiarowość, bo ich uczenie jest znacznie prostsze. W przeciwieństwie do np. PCA kodowanie uzyskane przez taki autoenkoder może być nieliniowe, tak więc zmienne ukryte mają więcej elastyczności w reprezentacji danych. Selekcja atrybutów, której podstawy omawialiśmy wcześniej na przedmiocie, również redukuje wymiarowość, ale nie zmienia informacji w atrybutach. W ogólności techniki redukcji wymiarowości tworzą zupełnie nowe atrybuty ze starych (np. $Y_1 = 0.5X_1 - 0.25X_2^2 + \\log_2 X_3$, gdzie $Y_1$ to nowy atrybut, a $X_i$ to oryginalne atrybuty). Wiele zastosowań autoenkoderów buduje właśnie na tej zdolności, a także na tym, że dzięki procesowi uczenia sieci tworzymy metodę redukcji wymiarowości zoptymalizowaną do konkretnego problemu.\n",
    "\n",
    "<br>\n",
    "\n",
    "Autoenkodery mają wiele potencjalnych zastosowań, przykładowo:\n",
    "* Redukcja wymiarowości - uczymy autoenkoder w trybie autoasocjacji, i naszym celem jest zmniejszenie wymiarowości danych, czyli zastąpienie oryginalnego obiektu jego wektorem zmiennych ukrytych. Można użyć jako alternatywy dla selekcji atrybutów i dedykowanych metod redukcji wymiarowości (PCA, LDA, etc.).\n",
    "* Grupowanie - uczymy autoenkoder w trybie autoasocjacji, wykorzystujemy wektory zmiennych ukrytych uzyskane dla danych uczących jako wejście do algorytmu grupowania (np. k-means).\n",
    "* Wyszukiwanie informacji - uczymy autoenkoder w trybie autoasocjacji, wykorzystujemy wektor zmiennych ukrytych jako hasz obiektu. Jeżeli chcemy znaleźć w bazie danych obiekty podobne do zadanego obiektu $X$, to generujemy wektor zmiennych ukrytych (hasz) $X$ przy użyciu enkodera i szukamy obiektów w zbiorze o najbardziej zbliżonych haszach. Technika ta nazywana jest haszowaniem semantycznym.\n",
    "* Wykrywanie anomalii - uczymy autoenkoder w trybie autoasocjacji wyłącznie na przypadkach \"normalnych\". Liczymy na to, że jak kiedykolwiek autoenkoder dostanie do przetworzenia przypadek odstający/anomalię, to nie da rady jej dobrze zrekonstruować i błąd będzie wysoki (właśnie przez to, że nie miał szansy się na nich nauczyć).\n",
    "* Generowanie danych - uczymy autoenkoder w trybie autoasocjacji, a następnie jak chcemy uzyskać różne warianty danego obrazu/obiektu, to modyfikujemy jego wygenerowany przez enkoder wektor zmiennych ukrytych, i dajemy go do przetworzenia dekoderowi. Możemy też po prostu losowo próbkować przestrzeń wektorów ukrytych i obserwować wyniki po przetworzeniu przez dekoder. Przy odrobinie szczęścia jakaś zmienna ukryta może np. odpowiadać za wyraz twarzy człowieka, i zmieniając wartości tej zmiennej możemy zmieniać wyłącznie wyraz twarzy człowieka na zdjęciu. Do tego zadania zazwyczaj wykorzystywany jest zmodyfikowany wariant autoenkodera: autoenkoder wariacyjny.\n",
    "* Odszumianie - uczymy autoenkoder w trybie heteroasocjacji: *zaszumiony obraz* -> *oryginalny obraz*. Liczymy na to, że enkoder i dekoder nauczą się poprawnie rozpoznawać szum jako element redundantny, nieniosący żadnej informacji.<br>\n",
    "![label-autoencoder_denoising](https://drive.google.com/uc?export=view&id=1a1fP7CWjzKSwo0txUBUMwaxTrpt6LzyH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApWipgI_LFh4"
   },
   "source": [
    "### Zadanie 6\n",
    "\n",
    "Zaimplementuj autoenkoder o następującej architekturze:\n",
    "* Enkoder: Dense(100) -> Dense(50) -> Dense(10) (wektor zmiennych ukrytych).\n",
    "* Dekoder: Dense (50) -> Dense(100) -> Dense(784) (wyjściowy zrekonstruowany obrazek)\n",
    "\n",
    "Funkcję aktywacji ustaw jako 'relu'. Jako miara błędu użyte zostanie MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fxxfRGsbvZZ"
   },
   "outputs": [],
   "source": [
    "# zmiany w funkcji train_and_test, tak aby dostosować ją do autoenkoderów.\n",
    "# na szczęście Colab i wbudowane Gemini przyszły z pomocą. Mam nadzieję że to jest ok, z racji że nie było to częścią zadania ;)\n",
    "\n",
    "def train_and_test(\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        metric=None,\n",
    "        epochs=10,\n",
    "        verbose=False\n",
    "    ):\n",
    "    epochs_history = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_metric = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.cuda()\n",
    "            # target = target.cuda() # This line is causing the issue.\n",
    "            # For autoencoder, the target is the input itself\n",
    "            target = data.view(-1, 784).cuda() # Reshape target to match autoencoder output\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(data)\n",
    "            loss = criterion(pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if verbose and batch_idx % 100 == 0:\n",
    "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            # train_metric += metric(pred, target) # This line might also cause an issue\n",
    "            # For autoencoders, accuracy is not a relevant metric. We can skip this line.\n",
    "        if verbose:\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            # train_metric /= len(train_loader.dataset) # Skip this line as well\n",
    "            print(f\"Train loss: {train_loss:.4f}\")\n",
    "            # print(f\"Train {metric.__name__}: {train_metric:.4f}\") # Skip this line\n",
    "\n",
    "        model.eval()\n",
    "        test_metric = 0\n",
    "        test_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data = data.cuda()\n",
    "            target = data.view(-1, 784).cuda() # Reshape target for test data as well\n",
    "            pred = model(data)\n",
    "            loss = criterion(pred, target)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            # test_metric += metric(pred, target) # Skip this line\n",
    "        if verbose:\n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            # test_metric /= len(test_loader.dataset) # Skip this line\n",
    "            print(f\"Test loss: {test_loss:.4f}\")\n",
    "            # print(f\"Test accuracy: {test_metric:.4f}\") # Skip this line\n",
    "            print(\"-------------------------------\")\n",
    "\n",
    "        epochs_history.append({\n",
    "          \"epoch\": epoch,\n",
    "          \"train_loss\": train_loss,\n",
    "          # f\"train_{metric.__name__}\": train_metric, # Skip this line\n",
    "          \"test_loss\": test_loss,\n",
    "          # f\"test_{metric.__name__}\": test_metric # Skip this line\n",
    "        })\n",
    "    return epochs_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZCTt7EiLFNS",
    "outputId": "3e4488dd-e32e-4f85-b1fa-812bccc2ad5d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 100), # Colab tutaj sam już autouzupełnia wszystkie warstwy, więc pewnie bardzo dobrze zna ten notatnik ;)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10),\n",
    "            # nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 784),\n",
    "            nn.Sigmoid() #o, a to colab sam z siebie dodał, ciekawe czy powinno tu być!\n",
    "        )\n",
    "\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure input is flattened\n",
    "        x = x.view(-1, 784)\n",
    "        # Encode\n",
    "        encoded = self.encoder(x)\n",
    "        # Decode\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Model creation\n",
    "model = Autoencoder().cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "_ = train_and_test(train_loader, test_loader, model, optimizer, criterion, metric=accuracy, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrWS4dxeNVeo"
   },
   "source": [
    "### Zadanie 7\n",
    "\n",
    "Użyj zaimplementowanego wyżej autoenkodera by zaobserwować jak zmienia się odtwarzany obraz gdy zmienia się tylko jeden element wektora zmiennych ukrytych. Zadanie wykonywane jest w następujących krokach:\n",
    "1. Użyj nauczonego enkodera z poprzedniego zadania na przypadku uczącym wybranej cyfry (dowolnej) by uzyskać wektor zmiennych ukrytych.\n",
    "2. Wybierz konkretną zmienną ukrytą w tym wektorze, np. tę o indeksie 0.\n",
    "3. W pętli podstawiaj różne wartości do tej zmiennej wektora z pewnym krokiem, i obserwuj obrazki generowane przez dekoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "ucUkv-MjNvmv",
    "outputId": "b404e993-8d0a-4252-dd44-3a9833863a2a"
   },
   "outputs": [],
   "source": [
    "example = train_data[0][0]\n",
    "print(\"Original image\")\n",
    "plt.imshow(example.reshape((28, 28)), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "x = np.expand_dims(example, 0) # Dodatkowy wymiar na pozycję przypadku w 'batchu', by wymiarowość się zgadzała\n",
    "\n",
    "# Po uczeniu wykonanym w poprzednim zadaniu, mamy dostęp do już nauczonych składowych sieci\n",
    "latent_vector = model.encoder(ToTensor(x).cuda())\n",
    "output = model.decoder(x)\n",
    "\n",
    "print(\"Reconstructed image\")\n",
    "plt.imshow(output.reshape(output, (28, 28)), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(f\"latent_vector: {latent_vector}\")\n",
    "\n",
    "for e in np.linspace(np.min(latent_vector), np.max(latent_vector), 11):\n",
    "  print(f\"e: {e}\")\n",
    "\n",
    "  # Zmień wektor zmiennych ukrytych, ustawiając wartość e w odpowiednim polu wektora\n",
    "  ...\n",
    "  # Użyj dekodera by wygenerować obrazek z nowego wektora zmiennych ukrytych\n",
    "  ...\n",
    "  # Pokaż wynikowy obrazek\n",
    "  ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQ8Iwz3sNsNO"
   },
   "source": [
    "### Zadanie 8\n",
    "\n",
    "Wykorzystaj kod z poprzednich zadań by nauczyć autoenkoder odszumiania. Parę uwag:\n",
    "* Musisz zmodyfikować zbiór uczący poprzez dodanie sztucznego szumu. Można to zrobić albo poprzez zmianę wartości kilku losowych pikseli w każdym obrazku, albo dodanie macierzy z małymi losowo generowanymi liczbami do obrazka (do każdego obrazka innej!). Oczekiwaną odpowiedzą podczas uczenia będzie oryginalny obrazek bez szumu.\n",
    "* Architektura enkodera i dekodera może pozostać bez zmian, ale będziesz musiał ją nauczyć na nowym zbiorze danych, tak więc by nie psuć wyników z zadania nr 6 sugeruję przeklejenie odpowiedniego kodu tutaj.\n",
    "* Zademonstruj działanie odszumiania poprzez pokazanie przypadku z szumem, a następnie zrekonstruowanego obrazka bez szumu po przetworzeniu przez autoenkoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_OMeKBPNuGZ"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv-snum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
